
# Intro to Probability

Probability helps us quantify uncertainty and make predictions about the likelihood of events.

---

## Sample Space and Events

- **Sample Space (S)**: The set of all possible outcomes of an experiment.
- **Event (E)**: A specific outcome or set of outcomes within the sample space.

**Think About This**

- **If you flip a fair coin, what is the sample space?**

T, H

- **If your event is getting heads, what is the outcome for this event?**

```{r, message = FALSE}
library(tidyverse)
# Simulate the sample space for flipping a coin
sample_space <- c("Heads", "Tails")

# Event: Getting Heads
event <- sample_space[1]

# Display results
sample_space
event
```

Type your answers below.

---

## Defining Probability

- **Probability (P)**: The likelihood that an event will occur, ranging from 0 (impossible) to 1 (certain).
  
**Example**:  
If you flip a fair coin, there are two possible outcomes: heads or tails. Each outcome has a probability of 0.5.

**Try It**:

- **What is the probability of drawing a face card from a standard deck of 52 cards?**

K, Q, J * 4 = 12

- **What is the probability of rolling an odd number on a fair six-sided die?**

1, 2, 3, 4, 5, 6

3/6


```{r}
# Probability of drawing a face card (12 face cards in a deck of 52)
prob_face_card <- 12 / 52

# Probability of rolling an odd number on a fair six-sided die
odd_numbers <- c(1, 3, 5)
prob_odd <- length(odd_numbers) / 6

# Display probabilities
prob_face_card
prob_odd
```

---

## Axioms of Probability

There are three fundamental axioms of probability:

1. **Non-Negativity**: Probability of any event is â‰¥ 0.
2. **Additivity**: For mutually exclusive events, the probability of their union is the sum of their probabilities.

mutual exclusive: event won't overlap: if one event happens, the other event will not happen  
ex: having size 6 feet and having size 8 feet  
P(size 6 or size 8) = P(size 6) + P(size 8)  

3. **Normalization**: The probability of the entire sample space is 1.

flipping a coin
P(H) = 0.5
P(T) = 0.5


**Activity**:  

- **If you roll a die, what is the probability of getting a number less than or equal 3?**  
0.5 

1, 2, 3, 4, 5, 6

3 / 6 = 0.5

- **What is the probability of rolling a number greater than 4?**
1/3 (0.333333)

1, 2, 3, 4, 5, 6

2/6 = 1/3 = 0.3333

```{r}
# Sample Space
sample_space <- c(1, 2, 3, 4, 5, 6)

# Probability of rolling a number less than 3
prob_less_than_equal_3 <- sum(sample_space <= 3) / length(sample_space)

# Probability of rolling a number greater than 4
prob_greater_than_4 <- sum(sample_space > 4) / length(sample_space)

# Display results
prob_less_than_equal_3
prob_greater_than_4
```

---

## Reflection

Now that we've covered some of the major concepts in study design and probability (last week and this week), take a moment to reflect on these questions:

- **What is the most important thing to remember when designing a study?**
- **How can understanding probability help in interpreting real-world situations?**

---

# Discrete Random Variable

Let $X$ be the number you get when rolling an unfair die.

| $x$      | 1   | 2   | 3    | 4   | 5   | 6    |
|:-------|:----|:----|:-----|:----|:----|:-----|
| $P(X=x)$ | 0.2 | 0.1 | 0.15 | 0.1 | 0.3 | 0.15 |

## Probability Mass Function (pmf)

pmf: f(x)

$P(X=1)=f(1)=0.2$

$P(X=2)=f(2)=0.1$

$P(X=3)=f(3)=0.15$

$P(X=4)=f(4)=0.1$

$P(X=5)=f(5)=0.3$

$P(X=6)=f(6)=0.15$

```{r, echo=F}
x <- 1:6
y <- c(0.2, 0.1, 0.15, 0.1, 0.3, 0.15)

data <- data.frame(x = x, y = y)

data %>% 
  ggplot() +
  aes(x = x, y = y) +
  geom_segment(data = data, 
               aes(x = x, y = 0, 
                   xend = x, yend = y)) +
  labs(x = expression(paste("x")),
       y = expression(paste("f(x)"))) +
  theme_bw() +
  theme(text = element_text(size = 20)) + 
  scale_x_continuous(breaks = pretty(data$x, n = 6))
```

## Cumulative Distribution Function (cdf)

| $x$      | 1   | 2   | 3    | 4   | 5   | 6    |
|:-------|:----|:----|:-----|:----|:----|:-----|
| $P(X\leq x)$ | 0.2 | 0.3 | 0.45 | 0.55 | 0.85 | 1 |

F(x)

F(3) = 0.45 = f(1) + f(2) + f(3)

F(4)

P(X <= 3) = 0.45 = P(X = 1) + P(X = 2) + P(X = 3)

P(X <= 4) = 0.55 = P(X <= 3) + P(X = 4)

P(X <= 5) = 0.85

P(X <= 1) = P(X = 1)

P(X <= 6) = 1

$P(X\leq1)=F(1)=0.2$

$P(X\leq2)=F(2)=0.3$

...

$P(X\leq6)=F(6)=1$

_Exercise 1: Fill in the cdf table using the pmf table._

_Exercise 2: If we were only given the completed cdf table, are we able to know the pmf of the random variable?_

f(1) = P(X = 1) = 0.2

f(2) = P(X = 2) = 0.1

f(3) = P(X = 3) = 0.15

P(X <= 2) = 0.3

P(X <= 2) = P(X = 1) + P(X = 2)

P(X = 1) = 0.2 = P(X <= 1)

P(2 <= X <= 5) = P(X = 2) + P(X = 3) + P(X = 4) + P(X = 5) 

_Exercise 3: What are $F(0), F(2.5), F(10)$?_

F(0) = P(X <= 0) = 0

F(2.5) = P(X <= 2.5) = 0.3

F(10) = P(X <= 10) = 1

1 - F(10) = P(X > 10) = 0

P(X > 3) = 1 - P(X <= 3) = 1 - 0.45 = 0.55

P(X >= 3) = 1 - P(X < 3) = 1 - P(X <= 2) = 0.7

```{r, echo=F}
x <- 1:6
y <- cumsum(c(0.2, 0.1, 0.15, 0.1, 0.3, 0.15))
xend <- c(2, 3, 4, 5, 6, 6)

data <- data.frame(x = x,
                   y = y,
                   xend = xend)

ggplot(data = data,
       aes(x = x, y = y, xend = xend, yend = y)) +
  geom_point() +
  geom_segment() +
  scale_x_continuous(breaks=1:6,
                     limits = c(1, 6)) +
  scale_y_continuous(limits = c(-.1, 1.1)) +
  labs(x = "x",
      y = expression(paste("F(x)")))+
  theme_bw() +
  theme(text = element_text(size = 20)) 
```

## Expectation

| $x$    | 1   | 2   | 3    | 4   | 5   | 6    |
|:-----|:----|:----|:-----|:----|:----|:-----|
| $f(x)$ | 0.2 | 0.1 | 0.15 | 0.1 | 0.3 | 0.15 |

$E[X]=\sum_{x\in S}xf(x)=1\times0.2  +2\times 0.1 +3\times  0.15 +4\times 0.1 +5\times  0.3 +6\times  0.15=3.65$


```{r}
x <- 1:6
f_x <- c(0.2, 0.1, 0.15, 0.1, 0.3, 0.15)
mu <- sum(x * f_x)
mu
```

## Variance

$Var(X)=E[(X-E[X])^2]=E[X^2]-(E[X])^2$, where

$E[X^2]=\sum_{x\in S}x^2f(x)=1^2\times0.2  +2^2\times 0.1 +3^2\times  0.15 +4^2\times 0.1 +5^2\times  0.3 +6^2\times  0.15=16.45$

and

$(E[X])^2=3.65^2=13.3225$

```{r}
mu_2 <- sum(x^2 * f_x)
mu_2 - mu^2
```

## Linear Combination of Random Variables

$E(aX+bY)=a\cdot E(X)+b\cdot E(Y)$

E(X + Y) = E(X) + E(Y)

E(2X + 3Y) = 2E(X) + 3E(Y)

$Var(aX+bY)=a^2\cdot Var(X)+b^2\cdot Var(Y)$ if $X$ and $Y$ are independent.

Var(2X + 3Y) = 4Var(X) + 9(Var(Y))

Var(2X) = 4*3.1275


Var(X) = 0.5, Var(Y) = 0.7  
Var(8X - 2Y) = 64Var(X) + 4Var(Y)






